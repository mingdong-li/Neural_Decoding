{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Point Process Decoder\n",
    "\n",
    "For use in point process decoding (sometimes it is also termed as point process filter), we need the following format of inputs:\n",
    "- Neural data should be a matrix of size \"number of time bins\" x \"number of neurons\", where each entry is the firing rate of a given neuron in a given time bin\n",
    "- It should be noted that point process decoding is for binary-valued spike trains. Hence, the time bins should be very small to gurantee that most intervals have no more than one spike.\n",
    "- The output you are decoding should be a matrix of size \"number of time bins\" x \"number of features you are decoding\"\n",
    "\n",
    "\n",
    "This example is similar to those shown in \"Examples_all_decoders.\"\n",
    "However, there is some preprocessing is different for Point Process decoders, so we have made a separate notebook.\n",
    "\n",
    "In this example notebook, we:\n",
    "1. Import the necessary packages\n",
    "2. Load a data file (spike trains and outputs we are predicting)\n",
    "3. Preprocess the data\n",
    "4. Check the intervals to gurantee the point process observation\n",
    "5. Run the point process decoders and print the goodness of fit\n",
    "6. Plot example decoded outputs\n",
    "7. evaluation method for point process decoder\n",
    "\n",
    "- A small time bin is used to obtain point process observation\n",
    "- State-space model with Gaussian approximation (Kalman FILTER with Point Process) [Link][1]\n",
    "- State-space model with sequential Monte Carlo (Particle FILTER with Point Process) [Link][2]\n",
    "\n",
    "\n",
    "We will put this data in the format described above, with the help of the functions \"bin_spikes\" and \"bin_output\" that are in the file \"preprocessing_funcs.py\"\n",
    "\n",
    "[1]: https://direct.mit.edu/neco/article/16/5/971/6831/Dynamic-Analysis-of-Neural-Encoding-by-Point\n",
    "[2]: https://direct.mit.edu/neco/article/21/10/2894/7426/Sequential-Monte-Carlo-Point-Process-Estimation-of]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n"
     ]
    }
   ],
   "source": [
    "###Import standard packages###\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "###Import functions for binning data for preprocessing###\n",
    "from Neural_Decoding.preprocessing_funcs import bin_spikes\n",
    "from Neural_Decoding.preprocessing_funcs import bin_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "The data for this example can be downloaded at this [link](https://www.dropbox.com/sh/n4924ipcfjqc0t6/AACPWjxDKPEzQiXKUUFriFkJa?dl=0&preview=s1_data_raw.mat)\n",
    "\n",
    "It was recorded by Raeed Chowdhury from Lee Miller's lab at Northwestern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Load Data###\n",
    "folder='data/' #ENTER THE FOLDER THAT YOUR DATA IS IN\n",
    "# folder='/Users/jig289/Dropbox/MATLAB/Projects/In_Progress/BMI/Processed_Data/' \n",
    "data=io.loadmat(folder+'s1_data_raw.mat')\n",
    "spike_times=data['spike_times'] #Load spike times of all neurons\n",
    "vels=data['vels'] #Load x and y velocities\n",
    "vel_times=data['vel_times'] #Load times at which velocities were recorded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt=.01 #Size of time bins (in seconds)\n",
    "t_start=vel_times[0] #Time to start extracting data - here the first time velocity was recorded\n",
    "t_end=vel_times[-1] #Time to finish extracting data - here the last time velocity was recorded\n",
    "downsample_factor=1 #Downsampling of output (to make binning go faster). 1 means no downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t start 1.17s and t end 3068.16s\n",
      "selected: t start 1.17s and t end 500.00s\n"
     ]
    }
   ],
   "source": [
    "print(\"t start %.2fs and t end %.2fs\"%(t_start,t_end))\n",
    "t_end = 500\n",
    "print(\"selected: t start %.2fs and t end %.2fs\"%(t_start,t_end))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put data in binned format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#When loading the Matlab cell \"spike_times\", Python puts it in a format with an extra unnecessary dimension\n",
    "#First, we will put spike_times in a cleaner format: an array of arrays\n",
    "spike_times=np.squeeze(spike_times)\n",
    "for i in range(spike_times.shape[0]):\n",
    "    spike_times[i]=np.squeeze(spike_times[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Raymond Mingdong\n",
    "Date: 2023-11-10 21:48:21\n",
    "Description: In User Settings Edit\n",
    "'''\n",
    "###Preprocessing to put spikes and output in bins###\n",
    "\n",
    "#Bin neural data using \"bin_spikes\" function\n",
    "neural_data=bin_spikes(spike_times,dt,t_start,t_end)\n",
    "\n",
    "#Bin output (velocity) data using \"bin_output\" function\n",
    "vels_binned=bin_output(vels,vel_times,dt,t_start,t_end,downsample_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the number of spikes in each intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural data shape:(49882,52)\n",
      "0.9932 intervals have no more than one spike\n"
     ]
    }
   ],
   "source": [
    "print(\"Neural data shape:(%d,%d)\"%(neural_data.shape[0],neural_data.shape[1]))\n",
    "no_spike = np.sum(neural_data==0)\n",
    "one_spike = np.sum(neural_data==1)\n",
    "more_than_one_spike = np.sum(neural_data>1)\n",
    "num_intervals = neural_data.shape[0]*neural_data.shape[1]\n",
    "\n",
    "# check the ratio\n",
    "print(\"%.4f intervals have no more than one spike\"%(1-more_than_one_spike/num_intervals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# data_folder='' #FOLDER YOU WANT TO SAVE THE DATA TO\n",
    "\n",
    "# with open(data_folder+'example_data_s1.pickle','wb') as f:\n",
    "#     pickle.dump([neural_data,vels_binned],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
